{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57602,"status":"ok","timestamp":1680941527196,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"fa_xJMzXdjMA","outputId":"10c57fa5-ccea-4874-d2dd-139159b1b1e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1030,"status":"ok","timestamp":1680941535974,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"vOqzsqdiedMD"},"outputs":[],"source":["ROOT_DIR = '/content/gdrive/MyDrive/Project'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680941538520,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"ZkQm-pJqeted","outputId":"f4cc00f0-5484-4495-8637-36142bed0308"},"outputs":[{"name":"stdout","output_type":"stream","text":["'00_VeraCrypt Containers'   Documents\t     Project\n","'Admit Card '\t\t   'Dot Files'\t     Report_Edited.docx\n","'Ankita Patra'\t\t    DotFiles\t    'Results '\n","'Avipsa Patra'\t\t   'MLBB '\t    'Semester - 5'\n","'Avisek Patra'\t\t   'Number Plate '  'Semester 6'\n","'BFL Receipt'\t\t    Obsidian\t    'Untitled document.gdoc'\n"]}],"source":["!ls /content/gdrive/MyDrive/"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1680941541798,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"9tzXDpYxe62J","outputId":"d992096c-7e5c-4d54-e7c9-18aaa63237a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7591,"status":"ok","timestamp":1680941551666,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"NEewkV8xfUaC","outputId":"3de13866-a558-44fe-a91e-b4ec5cc982ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imutils in /usr/local/lib/python3.9/dist-packages (0.5.4)\n"]}],"source":["!pip install imutils"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5754,"status":"ok","timestamp":1680941559732,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"-O0cwRaPfxvK","outputId":"d42d4e23-1af2-4517-b5e2-e5384d17b459"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n","Requirement already satisfied: numpy\u003e=1.17.3 in /usr/local/lib/python3.9/dist-packages (from opencv-contrib-python) (1.22.4)\n"]}],"source":["!pip install opencv-contrib-python"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7581,"status":"ok","timestamp":1680941570592,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"amNqJZd0f-EU","outputId":"53aa4f13-47b5-4015-c2c8-41c2442fbe59"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.70-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.1/510.1 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0)\n","Requirement already satisfied: seaborn\u003e=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: torch\u003e=1.7.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.0.0+cu118)\n","Collecting thop\u003e=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torchvision\u003e=0.8.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.15.1+cu118)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.27.1)\n","Requirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (8.4.0)\n","Requirement already satisfied: tqdm\u003e=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.65.0)\n","Requirement already satisfied: numpy\u003e=1.21.6 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.22.4)\n","Requirement already satisfied: matplotlib\u003e=3.2.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (3.7.1)\n","Collecting sentry-sdk\n","  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python\u003e=4.6.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (5.9.4)\n","Requirement already satisfied: pandas\u003e=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.4.4)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (3.0.9)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (1.4.4)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (0.11.0)\n","Requirement already satisfied: importlib-resources\u003e=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (5.12.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (1.0.7)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (4.39.3)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (2.8.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib\u003e=3.2.2-\u003eultralytics) (23.0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas\u003e=1.1.4-\u003eultralytics) (2022.7.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.9/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.4)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2.0.12)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2022.12.7)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch\u003e=1.7.0-\u003eultralytics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch\u003e=1.7.0-\u003eultralytics) (3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch\u003e=1.7.0-\u003eultralytics) (3.10.7)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch\u003e=1.7.0-\u003eultralytics) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch\u003e=1.7.0-\u003eultralytics) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch\u003e=1.7.0-\u003eultralytics) (3.1.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.7.0-\u003eultralytics) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.7.0-\u003eultralytics) (3.25.2)\n","Requirement already satisfied: zipp\u003e=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources\u003e=3.2.0-\u003ematplotlib\u003e=3.2.2-\u003eultralytics) (3.15.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.2.2-\u003eultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2-\u003etorch\u003e=1.7.0-\u003eultralytics) (2.1.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy-\u003etorch\u003e=1.7.0-\u003eultralytics) (1.3.0)\n","Installing collected packages: sentry-sdk, thop, ultralytics\n","Successfully installed sentry-sdk-1.19.1 thop-0.1.1.post2209072238 ultralytics-8.0.70\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6603,"status":"ok","timestamp":1680941581281,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"-xMUKz3mh-SH","outputId":"f27abfd2-7ada-4309-cc2d-f9233c2309a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.12.0)\n"]}],"source":["!pip install keras"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8384,"status":"ok","timestamp":1680941594014,"user":{"displayName":"AVISEK PATRA","userId":"02021794560097235956"},"user_tz":-330},"id":"AYDSW7OhiOId","outputId":"5a4fa985-410c-42b9-d5bf-d6f125cd96cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deskew\n","  Downloading deskew-1.4.3-py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from deskew) (1.22.4)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from deskew) (0.19.3)\n","Requirement already satisfied: tifffile\u003e=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (2023.3.21)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,\u003e=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (8.4.0)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (1.10.1)\n","Requirement already satisfied: imageio\u003e=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (2.25.1)\n","Requirement already satisfied: PyWavelets\u003e=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (1.4.1)\n","Requirement already satisfied: networkx\u003e=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (3.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image-\u003edeskew) (23.0)\n","Installing collected packages: deskew\n","Successfully installed deskew-1.4.3\n"]}],"source":["!pip install deskew"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1pKZKTMaKKbq0O0xpL5P3Wq9MgmPhbegu"},"id":"Z1-kyDb5guGC","outputId":"032fe980-33dd-4333-9216-b5b292c59c2a"},"outputs":[],"source":["import functools\n","import math\n","from typing import Union, Tuple\n","\n","import cv2\n","import numpy as np\n","from deskew import determine_skew\n","from imutils import paths\n","import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras.utils import img_to_array\n","from ultralytics import YOLO\n","from google.colab.patches import cv2_imshow\n","\n","\n","# Function from deskew to calculate rotation angle\n","def rotate(\n","        image: np.ndarray, angle: float, background: Union[int, Tuple[int, int, int]]\n",") -\u003e np.ndarray:\n","    old_width, old_height = image.shape[:2]\n","    angle_radian = math.radians(angle)\n","    width_ = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n","    height_ = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n","\n","    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n","    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n","    rot_mat[1, 2] += (width_ - old_width) / 2\n","    rot_mat[0, 2] += (height_ - old_height) / 2\n","    return cv2.warpAffine(image, rot_mat, (int(round(height_)), int(round(width_))), borderValue=background)\n","\n","\n","# Function to show output\n","def show_img(image):\n","    cv2_imshow(image)\n","    # cv2.waitKey(0)\n","    # cv2.destroyAllWindows()\n","\n","\n","def get_license_plate(stock_image):\n","    # Load the YOLOv8 Model\n","    model = YOLO('/content/gdrive/MyDrive/Project/weights/best.pt')\n","\n","    # Apply YOLOv8 model predictions and show the license plate\n","    results = model(stock_image)\n","\n","    plotted = results[0].plot(show_conf=True)\n","    show_img(plotted)\n","\n","    # Get the bounding box from YOLOv8 Model Prediction results\n","    box = results[0].boxes\n","    bbox = box.xyxy\n","    bbox = bbox.numpy()\n","\n","    # Store the XY Coordinates in integer format\n","    x1 = int(bbox[0, 0])\n","    y1 = int(bbox[0, 1])\n","    x2 = int(bbox[0, 2])\n","    y2 = int(bbox[0, 3])\n","\n","    # Now crop the license plate in the stock image\n","    cropped = stock_image[y1:y2, x1:x2]\n","    return cropped\n","\n","\n","def shadow_remove(img):\n","    rgb_planes = cv2.split(img)\n","    result_norm_planes = []\n","    for plane in rgb_planes:\n","        dilated_img = cv2.dilate(plane, np.ones((13, 13), np.uint8))\n","        bg_img = cv2.medianBlur(dilated_img, 35)\n","        diff_img = 255 - cv2.absdiff(plane, bg_img)\n","        norm_img = cv2.normalize(diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n","        result_norm_planes.append(norm_img)\n","    shadowremov = cv2.merge(result_norm_planes)\n","    return shadowremov\n","\n","\n","def preprocess_lPlate(image):\n","    # Show the Cropped License Plate\n","    show_img(image)\n","\n","    # Deskew\n","    angle = determine_skew(image)\n","    rotated = rotate(image, angle, (0, 0, 0))\n","    show_img(rotated)\n","\n","    # Remove shadows for cleaning license plate\n","    clear = shadow_remove(rotated)\n","    show_img(clear)\n","\n","    # Convert to gray scale\n","    gray = cv2.cvtColor(clear, cv2.COLOR_BGR2GRAY)\n","    show_img( gray)\n","\n","    # Denoise\n","    den = cv2.bilateralFilter(gray, 21, 75, 75)\n","    show_img(den)\n","\n","    # Threshold using Otsu's Thresholding\n","    thresh = cv2.threshold(den, 0, 200, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n","    show_img( thresh)\n","\n","    # Erosion \u0026 Dilation\n","    img_erode = cv2.erode(thresh, (3, 3))\n","    img_dilate = cv2.dilate(img_erode, (3, 3))\n","    show_img(img_dilate)\n","\n","    clean_license_plate(img_dilate, gray.shape)\n","    return img_dilate\n","\n","\n","def clean_license_plate(lic_plate, shape):\n","    # apply connected component analysis to the threshold image\n","    output = cv2.connectedComponentsWithStats(lic_plate, 4, cv2.CV_32S)\n","    (numLabels, labels, stats, centroids) = output\n","    # initialize an output mask to store all characters parsed from\n","    # the license plate\n","    mask = np.zeros(shape, dtype=\"uint8\")\n","    # loop over the number of unique connected component labels, skipping\n","    # over the first label (as label zero is the background)\n","    for i in range(1, numLabels):\n","        # extract the connected component statistics for the current\n","        # label\n","        x = stats[i, cv2.CC_STAT_LEFT]\n","        y = stats[i, cv2.CC_STAT_TOP]\n","        w = stats[i, cv2.CC_STAT_WIDTH]\n","        h = stats[i, cv2.CC_STAT_HEIGHT]\n","        area = stats[i, cv2.CC_STAT_AREA]\n","\n","        # print(w, h, area)\n","\n","        # ensure the width, height, and area are all neither too small\n","        # nor too big\n","        keepWidth = 20 \u003c w \u003c 60\n","        keepHeight = 75 \u003c h \u003c 115\n","        keepArea = 1250 \u003c area \u003c 4000\n","        # ensure the connected component we are examining passes all\n","        # three tests\n","        if all((keepWidth, keepHeight, keepArea)):\n","            # construct a mask for the current connected component and\n","            # then take the bitwise OR with the mask\n","            componentMask = (labels == i).astype(\"uint8\") * 255\n","            mask = cv2.bitwise_or(mask, componentMask)\n","            # show_img(\"mask\", mask)\n","\n","    show_img(mask)\n","    segment_lic_plate(mask)\n","    return mask\n","\n","\n","def segment_lic_plate(img):\n","    # Find contours and get bounding box for each contour\n","    contours, _ = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    boundingBoxes = [cv2.boundingRect(c) for c in contours]\n","\n","    # Sort the bounding boxes from left to right, top to bottom\n","    # sort by Y first, and then sort by X if Ys are similar\n","    def compare(rect1, rect2):\n","        if abs(rect1[1] - rect2[1]) \u003e 10:\n","            return rect1[1] - rect2[1]\n","        else:\n","            return rect1[0] - rect2[0]\n","\n","    boundingBoxes = sorted(boundingBoxes, key=functools.cmp_to_key(compare))\n","\n","    # Draw bounding boxes\n","    new = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","    for i in range(len(boundingBoxes)):\n","        x, y, w, h = boundingBoxes[i]\n","        cv2.rectangle(new, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","    show_img( new)\n","    apply_ocr(img, boundingBoxes)\n","    return new\n","\n","\n","def apply_ocr(image, boundingBoxes):\n","    color_img = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","    # Define constants\n","    TARGET_WIDTH = 128\n","    TARGET_HEIGHT = 128\n","\n","    chars = [\n","        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G',\n","        'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n","    ]\n","\n","    # Load the pre-trained convolutional neural network\n","    load = tensorflow.keras.models.load_model('/content/gdrive/MyDrive/Project/weights/characters_model.weights')\n","    vehicle_plate = \"\"\n","    # Loop over the bounding boxes\n","    for rect in boundingBoxes:\n","        # Get the coordinates from the bounding box\n","        x, y, w, h = rect\n","\n","        # Crop the character from the mask\n","        # and apply bitwise_not because in our training data for pre-trained model\n","        # the characters are black on a white background\n","        crop = image[y:y + h, x:x + w]\n","        crop = cv2.bitwise_not(crop)\n","\n","        # Get the number of rows and columns for each cropped image\n","        # and calculate the padding to match the image input of pre-trained model\n","        rows = crop.shape[0]\n","        columns = crop.shape[1]\n","        paddingY = (TARGET_HEIGHT - rows) // 2 if rows \u003c TARGET_HEIGHT else int(0.17 * rows)\n","        paddingX = (TARGET_WIDTH - columns) // 2 if columns \u003c TARGET_WIDTH else int(0.45 * columns)\n","\n","        # Apply padding to make the image fit for neural network model\n","        crop = cv2.copyMakeBorder(crop, paddingY, paddingY, paddingX, paddingX, cv2.BORDER_CONSTANT, None, 255)\n","\n","        # Convert and resize image\n","        crop = cv2.cvtColor(crop, cv2.COLOR_GRAY2RGB)\n","        crop = cv2.resize(crop, (TARGET_WIDTH, TARGET_HEIGHT))\n","        # show_img(\"Cropped Characters\", crop)\n","\n","        # Prepare data for prediction\n","        crop = crop.astype(\"float\") / 255.0\n","        crop = img_to_array(crop)\n","        crop = np.expand_dims(crop, axis=0)\n","\n","        # Make prediction\n","        prob = load.predict(crop)[0]\n","        idx = np.argsort(prob)[-1]\n","        vehicle_plate += chars[idx]\n","\n","        # Show bounding box and prediction on image\n","        cv2.rectangle(color_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        cv2.putText(color_img, chars[idx], (x - 15, y), font, 0.8, (0, 0, 255), 2)\n","\n","    show_img(color_img)\n","    print(\"Vehicle plate: \" + vehicle_plate)\n","    return vehicle_plate\n","\n","\n","# This is for mass input\n","IMG_PATH = '/content/gdrive/MyDrive/Project/bike_samples/'\n","filenames = sorted(list(paths.list_images(IMG_PATH)), reverse=False)\n","print(filenames)\n","\n","# Get the license plates using Y0L0v8 Model in the Predefined Resolution\n","for file in filenames:\n","    org_img = cv2.imread(file)\n","    img_cvt = cv2.resize(org_img, (1280, 720))\n","    # show_img(img_cvt)\n","\n","    # Detect License plate using YOLOv8 Model\n","    license_plate = get_license_plate(img_cvt)\n","\n","    # Resize for standardized size\n","    height, width, channels = license_plate.shape\n","    normal_format = license_plate\n","    if height \u003c 150 and width \u003c 350:\n","        normal_format = cv2.resize(license_plate, (500, 250), interpolation=cv2.INTER_CUBIC)\n","\n","    # Start ANPR\n","    lPlate = preprocess_lPlate(normal_format)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMzUkgZnChXulBCOLqxKWWT","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}